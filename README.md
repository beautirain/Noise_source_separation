ğŸ”Š Substation Transformer Noise Separation & Evaluation

Full dataset and evaluation details will be released after paper acceptance

A deep learningâ€“based framework for transformer noise extraction and acoustic evaluation under complex multi-source noise environments
ğŸ“Œ Project Overview
This repository presents a target-oriented noise source separation framework designed for substation transformer noise analysis and intelligent acoustic evaluation.

Unlike generic speech separation tasks, this project focuses on extracting steady-state transformer equipment noise from complex acoustic environments (urban noise, wind, rain, human activities, etc.), and quantitatively evaluating the separation quality using engineering-relevant acoustic metrics.
Key features:

ğŸ¯ Target source extraction (Transformer vs. All Other Noises)

ğŸ”Š Time-domain deep separation models (ConvTasNet / DPRNN / DPTNet)

ğŸ“Š Comprehensive evaluation metrics:

    SI-SDR improvement

    A-weighted SPL recovery error

    Spectral fidelity (SC, HEF)

ğŸŒ Robustness testing under multi-source interference

ğŸ“ˆ Visualization tools for spectra, spectrograms, and training curves
Core Idea
The project adopts a binary source separation strategy:


  Mixed Noise  
  
     â”œâ”€â”€ Transformer Noise (Target)
     â””â”€Non-Transformer Noise (All Interferences)
This formulation enables robust extraction of transformer noise even when multiple environmental noise sources coexist, which is more suitable for substation acoustic assessment than fine-grained multi-class separation.
   
   Project Structure
   .
   
    â”œâ”€â”€ checkpoints/                  # Trained model checkpoints
    â”œâ”€â”€ data_raw/                     # Raw long-duration recordings
    â”œâ”€â”€ data_clean_segments/          # Segmented clean transformer signals
    â”œâ”€â”€ data_mixtures/                # Two-source (transformer + noise) datasets
    â”œâ”€â”€ data_multisource/             # Multi-source interference datasets
    â”œâ”€â”€ noise_dir/                    # Environmental / urban noise library
    â”œâ”€â”€ target_dir/                   # Transformer noise library
    â”œâ”€â”€ separation_results/           # Separated audio outputs
    â”œâ”€â”€ eval_results/                 # Quantitative evaluation outputs
    â”‚
    â”œâ”€â”€ train_asteroid.py             # Model training script
    â”œâ”€â”€ run_separation.py             # Inference & separation
    â”‚
    â”œâ”€â”€ make_multisource_dataset.py   # Multi-source dataset generator
    â”œâ”€â”€ create_mixtures.py            # Two-source mixture generation
    â”œâ”€â”€ prepare_clean_segments.py     # Long audio segmentation
    â”‚
    â”œâ”€â”€ eval_multisource_target.py    # Target extraction evaluation (core)
    â”œâ”€â”€ eval_spl_error.py             # A-weighted SPL error evaluation
    â”œâ”€â”€ eval_spectrum_metrics.py      # Spectral fidelity metrics
    â”‚
    â”œâ”€â”€ plot_loss_curves.py            # Training curves visualization
    â”œâ”€â”€ plot_model_compare.py         # Model performance comparison
    â”œâ”€â”€ plot_spectrogram_heatmap.py   # Spectrogram heatmaps
    â”œâ”€â”€ plot_spectrum_compare.py      # Spectrum comparison
    â”œâ”€â”€ plot_spectrum_bar.py           # Spectrum metric bar charts
    â”‚
    â””â”€â”€ README.md

Supported Models
Implemented via Asteroid framework:
  | Model      | Description                    | Characteristics                               |
  | ---------- | ------------------------------ | --------------------------------------------- |
  | ConvTasNet | Temporal convolutional network | Stable, efficient, best overall balance       |
  | DPRNN      | Dual-path RNN                  | Strong sequence modeling, risk of overfitting |
  | DPTNet     | Transformer-based              | High capacity, optimization sensitive         |

All models are trained as 2-output separators (target vs. interference).

ğŸ“Š Evaluation Metrics

1ï¸âƒ£ SI-SDR Improvement (SI-SDRi)

  Measures source separation quality relative to the input mixture:
  
  SI-SDRğ‘–=SI-SDRestâˆ’SI-SDRmix
  
2ï¸âƒ£ A-weighted Sound Pressure Level (SPL) Error

  Evaluates engineering accuracy of extracted transformer noise:
  
  Î”ğ¿ğ´=ğ¿ğ´,estâˆ’ğ¿ğ´,true
  
  Reported as:
  Mean / max absolute error
    
  Percentage of samples with âˆ£Î”ğ¿ğ´âˆ£<1 dB
    
3ï¸âƒ£ Spectral Fidelity Metrics

  SC (Spectral Correlation)
  
  Measures similarity of spectral shape

    
  HEF (Harmonic Energy Fidelity)
  
  Quantifies recovery of harmonic energy at fundamental and multiples
    
ğŸ§ª Multi-Source Robustness Evaluation

To assess real-world robustness, multi-source mixtures are generated:

  Transformer + Noise_1 + Noise_2 + ... + Noise_K
  
The model still outputs 2 channels, and the target transformer channel is automatically identified using:
  Spectral correlationâ€“based channel selection
  
  (Optional) SI-SDR oracle selection for upper-bound analysis
Quick Start

1ï¸âƒ£ Train a model

    python train_asteroid.py --model_type convtasnet --mode train
    
2ï¸âƒ£ Generate multi-source dataset

    python make_multisource_dataset.py \
      --target_dir target_dir \
      --noise_dir noise_dir \
      --out_root data_multisource \
      --seg_sec 4 \
      --train 6000 --val 600 --test 600 \
      --kmin 3 --kmax 6
      
3ï¸âƒ£ Evaluate target extraction (recommended)

    python eval_multisource_target.py \
      --data_root data_multisource \
      --model_type convtasnet \
      --ckpt checkpoints/convtasnet_epoch30.pth \
      --pick_method spec \
      --f0 100
      
ğŸ“ˆ Visualization

Training convergence curves

Spectrogram heatmaps (true vs separated vs mixed)

Spectrum comparison plots

Metric bar charts across models

All plotting scripts are under plot_*.py.

ğŸ§© Design Philosophy

âœ” Focus on engineering relevance, not only signal-level metrics

âœ” Target-oriented extraction instead of over-complicated multi-class separation


âœ” Modular and reproducible experimental pipeline

ğŸ“š Potential Extensions

Multi-target extraction (transformer + reactor + corona)

Online real-time deployment on NI PXIe platforms

Integration with fuzzy logicâ€“based acoustic impact assessment

Joint separation + classification architecture

ğŸ“œ License

This project is intended for academic research and engineering applications.

Please cite or acknowledge if used in publications.
ğŸ™Œ Acknowledgements

Asteroid for separation framework

Open environmental noise datasets
